{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import distributions\n",
    "\n",
    "import pickle\n",
    "\n",
    "# add utilities directory to path\n",
    "import os, sys\n",
    "util_path = os.path.abspath('utilities_and_data')\n",
    "if util_path not in sys.path and os.path.exists(util_path):\n",
    "    sys.path.insert(0, util_path)\n",
    "\n",
    "# import from utilities\n",
    "import stan_utility\n",
    "import stan_helper\n",
    "\n",
    "import pystan\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "font = {'family' : 'normal',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 22}\n",
    "import matplotlib\n",
    "matplotlib.rc('font', **font)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from psis import psisloo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stan_model(model_name, model_code, get_new=False):\n",
    "    path = os.path.abspath(os.path.join(os.path.curdir, model_name))\n",
    "\n",
    "    if not get_new and os.path.exists(path):\n",
    "        print(\"Model exists already! Returning pickle.\")\n",
    "        return pickle.load(open(path, 'rb'))\n",
    "    \n",
    "    print(\"Path doesn't exist. Compiling model. It might take few minutes...\")\n",
    "    import pystan\n",
    "    sm = pystan.StanModel(model_code=model_code)\n",
    "    with open(model_name, 'wb') as f:\n",
    "        pickle.dump(sm, f)\n",
    "    return sm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = np.loadtxt(\"data/factory.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) hierarchical model\n",
    "\n",
    "Hierarchical modeling is a statistically rigorous way to make scientific inferences about a population based on many groups/observations. Humanly speaking, it's a middle ground between pooling and separate modeling. We will have the same formula as separate:\n",
    "\n",
    "$$ y_{i,m} = \\alpha_m + \\beta_m \\times \\text{machine}_{i,m} + \\epsilon_m $$\n",
    "\n",
    "But $\\alpha$ and $\\beta$ come from a common group distribution:\n",
    "\n",
    "$$\\alpha_{c} \\sim \\mathcal{N}(\\mu_{\\alpha}, \\sigma_{\\alpha}^2)$$\n",
    "$$\\beta_{c} \\sim \\mathcal{N}(\\mu_{\\beta}, \\sigma_{\\beta}^2)$$\n",
    "\n",
    "So we model coefficients and predictions. That's why it's called hierarchical/multilevel modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30,) (30,) 30\n"
     ]
    }
   ],
   "source": [
    "x = np.tile(np.arange(1, 7), d.shape[0])\n",
    "y = d.ravel();y\n",
    "N = len(x)\n",
    "data = dict(\n",
    "    N = N,\n",
    "    K = 7,  # 6 machines\n",
    "    x = x,  # group indicators\n",
    "    y = y,   # observations\n",
    "    target_machine = 6  # 6th machine\n",
    ")\n",
    "print(x.shape,y.shape,N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our linear model:\n",
    "$$ y = \\beta_0 + \\beta_1 \\times x + e $$\n",
    "\n",
    "$e$ is an error term sampled from $N(\\mu, \\sigma)$\n",
    "\n",
    "Priors for each machine is not fixed, but rather depend on other latent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Comparison of k groups with common variance and\n",
    "#  hierarchical prior for the mean\n",
    "\n",
    "data_code = '''\n",
    "data {\n",
    "    int<lower=0> N; // number of data points\n",
    "    int<lower=0> K; // number of groups\n",
    "    int<lower=1,upper=K> x[N]; // group indicator\n",
    "    vector[N] y; //\n",
    "    int<lower=0> target_machine;\n",
    "}\n",
    "parameters {\n",
    "    real<lower=70, upper=110> mu0; // uniform prior mean\n",
    "    real<lower=0, upper=20> sigma0; // uniform prior std\n",
    "    vector[K] mu;         // group means\n",
    "    real<lower=0> sigma;  // common std\n",
    "}\n",
    "model {\n",
    "  mu ~ normal(mu0, sigma0); // population prior with unknown parameters\n",
    "  y ~ normal(mu[x], sigma);\n",
    "  //for (i in 1:N)\n",
    "  //mu7 ~ normal(mu0, sigma0);  // Is this correct? Idk. mu7 ~ normal(mu0, sigma0) gave me low mean around 19.\n",
    "}\n",
    "generated quantities {\n",
    "  real ypred;\n",
    "  real mu7;\n",
    "  real ypred7;\n",
    "  vector[6] ypred_all;\n",
    "  vector[N] log_lik;\n",
    "  ypred = normal_rng(mu[target_machine], sigma);\n",
    "  for (i in 1:N)\n",
    "    log_lik[i] = normal_lpdf(y[i] | mu[x[i]], sigma);\n",
    "    \n",
    "  mu7 = normal_rng(mu0,sigma0);\n",
    "  ypred7 = normal_rng(mu7, sigma);\n",
    "  \n",
    "  for (i in 1:6)\n",
    "    ypred_all[i] = normal_rng(mu[i], sigma);\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model exists already! Returning pickle.\n"
     ]
    }
   ],
   "source": [
    "# sm_hierarchical =  get_stan_model(\"factory_hierarchical_posterior\", data_code, get_new=True)\n",
    "sm_hierarchical =  get_stan_model(\"factory_hierarchical_posterior\", data_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inference for Stan model: anon_model_b90bc0e16312b4e8431f9ae51b62b3a4.\n",
       "10 chains, each with iter=4000; warmup=2000; thin=1; \n",
       "post-warmup draws per chain=2000, total post-warmup draws=20000.\n",
       "\n",
       "               mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
       "mu0           92.87    0.05   5.79  80.88  89.25  92.96  96.62 104.22  15512    1.0\n",
       "sigma0        12.19    0.08    4.1   3.94   9.21  12.16  15.37  19.38   2446    1.0\n",
       "mu[0]         80.85     0.1   6.75  68.03   76.2  80.81  85.33  94.72   4718    1.0\n",
       "mu[1]        102.41    0.06   6.37  89.93  98.18 102.48 106.66 114.92  10669    1.0\n",
       "mu[2]         89.22    0.04   6.05   77.4  85.24  89.22  93.29 101.07  20000    1.0\n",
       "mu[3]        106.22    0.09   6.82   92.8 101.66 106.33 110.87 119.13   5593    1.0\n",
       "mu[4]         90.79    0.04   6.04   78.8  86.86  90.77  94.78 102.67  20000    1.0\n",
       "mu[5]         88.01    0.06   6.19  75.75   83.9  88.08  92.16 100.04  10732    1.0\n",
       "mu[6]         92.78    0.11  14.02  64.32   84.5   92.9 101.05 121.37  17376    1.0\n",
       "sigma         15.33    0.03   2.42  11.42  13.61  15.03  16.75   21.0   9086    1.0\n",
       "ypred         87.96    0.12  16.87  54.87   76.8   87.9  98.96 121.74  18966    1.0\n",
       "mu7           92.82     0.1  14.03  63.64  84.55  92.85 101.26 121.25  18109    1.0\n",
       "ypred7        92.65    0.15  20.89  51.31  78.92  92.63 106.16 134.41  19836    1.0\n",
       "ypred_all[0]   80.7    0.13  16.78  48.35  69.63  80.47  91.46 114.62  16851    1.0\n",
       "ypred_all[1] 102.34    0.13  16.83  68.29  91.38 102.62 113.36 135.09  17644    1.0\n",
       "ypred_all[2]   89.3    0.12  16.89  56.02  77.97  89.45 100.35 123.02  19336    1.0\n",
       "ypred_all[3] 106.24    0.13  16.84  72.41  95.23 106.45 117.45 138.87  15831    1.0\n",
       "ypred_all[4]  90.95    0.12  16.47  58.52  80.11  91.04  101.6 123.52  20000    1.0\n",
       "ypred_all[5]   87.9    0.12  16.74  54.85  76.93  87.77  98.76  121.2  19135    1.0\n",
       "log_lik[0]    -3.75  2.2e-3    0.2   -4.2  -3.86  -3.73  -3.61  -3.42   8413    1.0\n",
       "log_lik[1]    -4.19  3.7e-3   0.41  -5.15  -4.42  -4.12  -3.88  -3.57  12134    1.0\n",
       "log_lik[2]    -4.04  2.4e-3   0.34  -4.89  -4.21  -3.97   -3.8  -3.55  20000    1.0\n",
       "log_lik[3]    -3.74  2.2e-3    0.2  -4.19  -3.86  -3.72   -3.6  -3.41   8266    1.0\n",
       "log_lik[4]    -4.03  2.7e-3   0.34  -4.86   -4.2  -3.97  -3.79  -3.54  15680    1.0\n",
       "log_lik[5]    -5.88  6.7e-3   0.94  -8.04  -6.42  -5.76  -5.21   -4.4  20000    1.0\n",
       "log_lik[6]    -4.04  3.1e-3   0.37   -5.0   -4.2  -3.95  -3.78  -3.56  14497    1.0\n",
       "log_lik[7]    -3.81  2.8e-3   0.25   -4.4  -3.95  -3.77  -3.63  -3.42   8157    1.0\n",
       "log_lik[8]    -3.75  1.9e-3    0.2  -4.21  -3.86  -3.73  -3.61  -3.42  11688    1.0\n",
       "log_lik[9]    -4.08  5.3e-3    0.4  -5.02  -4.31  -4.01  -3.79  -3.51   5540    1.0\n",
       "log_lik[10]    -3.8  2.0e-3   0.24  -4.37  -3.92  -3.77  -3.64  -3.44  13493    1.0\n",
       "log_lik[11]   -3.76  2.0e-3   0.21  -4.24  -3.87  -3.73  -3.62  -3.42  11448    1.0\n",
       "log_lik[12]   -4.04  3.1e-3   0.37   -5.0   -4.2  -3.95  -3.78  -3.56  14497    1.0\n",
       "log_lik[13]   -4.01  3.5e-3   0.35  -4.83   -4.2  -3.96  -3.76   -3.5  10018    1.0\n",
       "log_lik[14]   -3.73  1.9e-3   0.19  -4.16  -3.84  -3.72   -3.6  -3.41  10749    1.0\n",
       "log_lik[15]   -3.93  4.7e-3   0.33  -4.72  -4.12  -3.87  -3.69  -3.45   5006    1.0\n",
       "log_lik[16]   -4.06  2.5e-3   0.35  -4.93  -4.23  -3.99  -3.81  -3.56  20000    1.0\n",
       "log_lik[17]   -4.32  3.8e-3   0.48  -5.51  -4.55  -4.21  -3.98  -3.67  15461    1.0\n",
       "log_lik[18]   -6.43  7.8e-3    1.1  -8.92   -7.1  -6.31  -5.64  -4.66  20000    1.0\n",
       "log_lik[19]   -3.73  2.2e-3    0.2  -4.16  -3.84  -3.71  -3.59   -3.4   8014    1.0\n",
       "log_lik[20]   -3.74  2.2e-3    0.2  -4.19  -3.85  -3.72   -3.6  -3.41   8361    1.0\n",
       "log_lik[21]   -3.78  1.9e-3   0.22  -4.32   -3.9  -3.76  -3.63  -3.44  13543    1.0\n",
       "log_lik[22]   -4.03  2.7e-3   0.34  -4.86   -4.2  -3.97  -3.79  -3.54  15680    1.0\n",
       "log_lik[23]   -3.98  3.0e-3   0.33  -4.76  -4.17  -3.93  -3.75   -3.5  11994    1.0\n",
       "log_lik[24]   -4.14  5.8e-3   0.42   -5.1  -4.38  -4.08  -3.83  -3.53   5172    1.0\n",
       "log_lik[25]   -4.29  3.8e-3   0.47  -5.49  -4.52  -4.18  -3.94  -3.67  15555    1.0\n",
       "log_lik[26]   -4.83  4.4e-3   0.62  -6.28  -5.17  -4.73  -4.38   -3.9  20000    1.0\n",
       "log_lik[27]   -3.93  4.7e-3   0.33  -4.72  -4.12  -3.87  -3.69  -3.45   5006    1.0\n",
       "log_lik[28]   -3.72  1.9e-3   0.19  -4.13  -3.83   -3.7  -3.59   -3.4   9486    1.0\n",
       "log_lik[29]   -4.06  2.8e-3   0.36  -4.99  -4.23  -3.98  -3.81  -3.57  16430    1.0\n",
       "lp__         -110.2    0.06   2.91 -116.7 -111.9 -109.9 -108.2 -105.6   2131    1.0\n",
       "\n",
       "Samples were drawn using NUTS at Thu Nov 16 15:23:55 2017.\n",
       "For each parameter, n_eff is a crude measure of effective sample size,\n",
       "and Rhat is the potential scale reduction factor on split chains (at \n",
       "convergence, Rhat=1)."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_hierarchical = sm_hierarchical.sampling(data=data, seed=194838, chains=10, iter=4000);fit_hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract samples in different forms for different parameters.\n",
    "# permuted : bool\n",
    "#    If True, returned samples are permuted. All chains are\n",
    "#    merged and warmup samples are discarded.\n",
    "samples_hierarchical = fit_hierarchical.extract(permuted=True)\n",
    "\n",
    "# stan_utility.check_treedepth(fit_hierarchical)\n",
    "# stan_utility.check_energy(fit_hierarchical)\n",
    "# stan_utility.check_div(fit_hierarchical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_likelihood_hierarchical = samples_hierarchical['log_lik'];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*log_likelihood* is an S-by-n matrix, where S is the number of posterior draws and n = 30 is the total number of observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood and posterior\n",
    "\n",
    "|Quality | Likelihood | Posterior |\n",
    "|-|:-:|:-:|\n",
    "|Good|||\n",
    "|Bad| | |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![simulation_methods.png](images/simulation_methods.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For each of the six machines, compute and report the expected utility of the products of that machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==Expected utility of the products of six machinee.==\n",
      "1th machine's Expected utility of the products: $33.33\n",
      "2th machine's Expected utility of the products: $0.00\n",
      "3th machine's Expected utility of the products: $33.33\n",
      "4th machine's Expected utility of the products: $33.33\n",
      "5th machine's Expected utility of the products: $100.00\n",
      "6th machine's Expected utility of the products: $33.33\n"
     ]
    }
   ],
   "source": [
    "# Expected Utility for Machine 1\n",
    "def get_expected_utility(machine_num):\n",
    "    utility_sum = 0\n",
    "    S = len(samples_hierarchical['ypred_all'][machine_num])\n",
    "    for i in range(S):\n",
    "        if samples_hierarchical['ypred_all'][machine_num][i] < 85:\n",
    "            utility_sum -= 100\n",
    "        else :\n",
    "            utility_sum += 100\n",
    "    return utility_sum / S\n",
    "\n",
    "expected_utilities = [get_expected_utility(i) for i in range(6)]; \n",
    "print(\"==Expected utility of the products of six machinee.==\")\n",
    "for i in range(len(expected_utilities)):\n",
    "    print(\"{}th machine's Expected utility of the products: ${:.2f}\".format(i+1, expected_utilities[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank the machines based on the expected utilities and explain briefly what these values tell about the quality of these machines. E.g. Tell which machines are profitable and which are not (if any)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Rank|Machine|Expected utility of products|\n",
    "|:-:|:-:|-:|\n",
    "|1|5|\\$100.00|\n",
    "|2|1|\\$33.33|\n",
    "|3|3|\\$33.33|\n",
    "|4|4|\\$33.33|\n",
    "|5|5|\\$33.33|\n",
    "|6|2|\\$0.00|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute and report the expected utility of the products of a new (7th) machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==Expected utility of the products of 7th machine.==\n",
      "7th machine's Expected utility of the products: $29.79\n"
     ]
    }
   ],
   "source": [
    "def get_7th_expected_utility():\n",
    "    utility_sum = 0\n",
    "    S = len(samples_hierarchical['ypred7'])\n",
    "    for i in range(S):\n",
    "        if samples_hierarchical['ypred7'][i] < 85:\n",
    "            utility_sum -= 100\n",
    "        else :\n",
    "            utility_sum += 100\n",
    "    return utility_sum / S\n",
    "\n",
    "expected_utility_7th = get_7th_expected_utility()\n",
    "print(\"==Expected utility of the products of 7th machine.==\")\n",
    "print(\"7th machine's Expected utility of the products: ${:.2f}\".format(expected_utility_7th))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Machine|Expected utility of products|\n",
    "|:-:|-:|\n",
    "|1|\\$33.33|\n",
    "|2|\\$0.00|\n",
    "|3|\\$33.33|\n",
    "|4|\\$33.33|\n",
    "|5|\\$100.00|\n",
    "|6|\\$33.33|\n",
    "|7|\\$29.79|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Based on your analysis, discuss briefly whether the company owner should buy a new (7th) machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected utility of products is $29.79 which generates profit. Thus the owner should buy a new one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignore below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Decision d | good quality | bad quality |\n",
    "|-|:-:|:-:|\n",
    "|Not Buy|0|0|\n",
    "|Buy| +100| -100|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility matrix U(x)\n",
    "\n",
    "|Action d | Conditioinal utility |\n",
    "|-|:-:|:-:|\n",
    "|Not Buy|0|\n",
    "|Buy| |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
